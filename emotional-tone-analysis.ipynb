{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'negative', 'score': 0.9731943011283875}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Force PyTorch backend manually\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# Load FinBERT\n",
    "analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", framework=\"pt\")\n",
    "\n",
    "text = \"Regulatory concerns led to a decline in investor confidence.\"\n",
    "result = analyzer(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pandas 2.2.3\n",
      "Uninstalling pandas-2.2.3:\n",
      "  Successfully uninstalled pandas-2.2.3\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/lib/python3.13/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alyssaspasic/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alyssaspasic/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "Successfully installed pandas-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pandas -y\n",
    "!pip install --no-cache-dir pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load stock emotions model\n",
    "stock_emotion_pipeline = pipeline(\"text-classification\", model=\"finance-ml/stock-emotions-bert\")\n",
    "\n",
    "# Test with a sample from your dataset\n",
    "test_text = \"Tesla stock is crashing! I'm really worried about my investments. 😟\"\n",
    "result = stock_emotion_pipeline(test_text)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Load & Preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           processed   emo_label\n",
      "0  Amazon Dow futures up by 100 points already  [...  excitement\n",
      "1  Tesla Daddy's drinkin' eArly tonight! Here's t...  excitement\n",
      "2  Apple We’ll been riding since last December fr...   confusion\n",
      "3  Tesla happy new year, 2020, everyone [wine gla...  excitement\n",
      "4  Tesla haha just a collection of greats...\"Mars...  excitement\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"train_stockemo.csv\")\n",
    "\n",
    "# Keep only the needed columns\n",
    "df = df[['processed', 'emo_label']]  \n",
    "\n",
    "# Remove NaN values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Check dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Labels to Numerical Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert dataframe to dataset format\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Encode emotion labels\n",
    "label_encoder = LabelEncoder()\n",
    "dataset = dataset.add_column(\"labels\", label_encoder.fit_transform(dataset[\"emo_label\"]))\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "valid_dataset = train_test_split[\"test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data for Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 6400, Testing size: 1600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['processed'].tolist(), df['emo_label'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training size: {len(train_texts)}, Testing size: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load FinBERT Model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m hidden_size = model.config.hidden_size  \u001b[38;5;66;03m# Usually 768 for BERT models\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Replace the classification head\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m model.classifier = \u001b[43mnn\u001b[49m.Linear(hidden_size, num_labels)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Update model configuration\u001b[39;00m\n\u001b[32m     15\u001b[39m model.config.num_labels = num_labels\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Set num_labels dynamically based on your dataset\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# Load FinBERT with correct num_labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "hidden_size = model.config.hidden_size  # Usually 768 for BERT models\n",
    "\n",
    "# Replace the classification head\n",
    "model.classifier = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "# Update model configuration\n",
    "model.config.num_labels = num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data into PyTorch Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load FinBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "class FinancialDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], truncation=True, padding=\"max_length\", \n",
    "            max_length=128, return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FinancialDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = FinancialDataset(test_texts, test_labels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train FinBERT on the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "# Ensure num_labels is set correctly\n",
    "num_labels = len(set(train_labels))  # Get unique labels count\n",
    "\n",
    "# Load FinBERT with correct number of labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=num_labels)\n",
    "\n",
    "# Use Data Collator for automatic padding\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finbert-emotion\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,  # Keeps last 2 checkpoints\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,  # Important for padding\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train FinBERT\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Save fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./finbert-emotion-model\")\n",
    "tokenizer.save_pretrained(\"./finbert-emotion-model\")\n",
    "\n",
    "# Load fine-tuned model for inference\n",
    "emotion_analyzer = pipeline(\n",
    "    \"text-classification\", \n",
    "    model=\"./finbert-emotion-model\", \n",
    "    tokenizer=\"./finbert-emotion-model\",\n",
    "    device=0 if torch.cuda.is_available() else \"mps\"  # Use GPU if available\n",
    ")\n",
    "\n",
    "# Test a financial statement\n",
    "text = \"The stock market crash is making investors panic.\"\n",
    "result = emotion_analyzer(text)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
