{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\python312\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\python312\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\python312\\lib\\site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\python312\\lib\\site-packages (from google-generativeai) (2.162.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\python312\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from google-generativeai) (5.29.1)\n",
      "Requirement already satisfied: pydantic in c:\\python312\\lib\\site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from google-generativeai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\seanm\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\seanm\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0rc2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0rc2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\python312\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\seanm\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seanm\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seanm\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seanm\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\python312\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your API key\n",
    "ci_api_key = os.getenv(\"CI_API_KEY\")\n",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=ci_api_key)\n",
    "\n",
    "# Function to detect emotional tone and relevance to the company\n",
    "def generate_emotion_and_relevance(text, company_name):\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")  # Define the model\n",
    "\n",
    "    # Define input text\n",
    "    input_text = f\"\"\"\n",
    "    Analyze the following financial article and determine whether it is relevant to the company named \"{company_name}\". \n",
    "    If the article is relevant to the company, please categorize the emotions that this article will evoke towards the company, \n",
    "    focusing on how the content affects the company's image or perception.\n",
    "    Categorize these emotions into the following categories:\n",
    "    optimism, anxiety, sadness, surprise, neutral, anger/disgust.\n",
    "    Please output the emotion for each category, with a confidence score between 1 and 10 for each emotion.\n",
    "    If the article is not relevant to the company, do not return emotional scores and simply state 'Not relevant to the company'.\n",
    "    The text is:\n",
    "    {text}\n",
    "\n",
    "    The output should be in the following format:\n",
    "    {{\n",
    "        \"relevant\": true/false,  # Whether the article is relevant to the company\n",
    "        \"optimism\": confidence_score (1-10),\n",
    "        \"anxiety\": confidence_score (1-10),\n",
    "        \"sadness\": confidence_score (1-10),\n",
    "        \"surprise\": confidence_score (1-10),\n",
    "        \"neutral\": confidence_score (1-10),\n",
    "        \"anger_disgust\": confidence_score (1-10)\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate content from model\n",
    "    try:\n",
    "        response = model.generate_content(input_text)\n",
    "        # Combine response text\n",
    "        response_text = \"\".join([chunk.text for chunk in response])\n",
    "\n",
    "        # Clean up the response\n",
    "        cleaned_text = re.sub(r\"```json|```\", \"\", response_text).strip()\n",
    "\n",
    "        # Convert response to JSON\n",
    "        output_json = json.loads(cleaned_text)\n",
    "        return output_json\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing article: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of common suffixes to remove\n",
    "SUFFIXES = [' Inc.', ' Ltd.', ' LLC', ' Corp.', ' Corporation', ' Co.', ' Group']\n",
    "\n",
    "# Function to calculate average emotional scores for each year and fill the graph CSV\n",
    "def process_articles_and_update_graph(csv_file, company_name, ticker_graph_csv, batch_size=10):\n",
    "    # Dictionary to store the emotional scores for each year\n",
    "    year_emotions = {}\n",
    "\n",
    "    # Open the CSV file and read articles\n",
    "    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Accumulate articles in a batch\n",
    "        batch_articles = []\n",
    "        \n",
    "        # Process each article and calculate emotions\n",
    "        for row in reader:\n",
    "            title = row['Title']\n",
    "            published_at = row['PublishedAt']\n",
    "            full_content = row['FullContent']\n",
    "            year = datetime.strptime(published_at, \"%Y-%m-%dT%H:%M:%S%z\").year\n",
    "            month = datetime.strptime(published_at, \"%Y-%m-%dT%H:%M:%S%z\").month\n",
    "\n",
    "            print(f\"Processing article: {title}\")\n",
    "            \n",
    "            # Add article to the current batch\n",
    "            batch_articles.append((full_content, company_name, year, month))\n",
    "\n",
    "            # If the batch size is reached, process the batch\n",
    "            if len(batch_articles) == batch_size:\n",
    "                print(f\"Processing batch of {batch_size} articles...\")\n",
    "                \n",
    "                # Process each article in the batch\n",
    "                for article in batch_articles:\n",
    "                    emotion_scores = generate_emotion_and_relevance(article[0], article[1])\n",
    "                    \n",
    "                    # If the article is relevant, update the emotional scores\n",
    "                    if \"relevant\" in emotion_scores and emotion_scores[\"relevant\"] == True:\n",
    "                        optimism = emotion_scores.get('optimism', 0)\n",
    "                        anxiety = emotion_scores.get('anxiety', 0)\n",
    "                        sadness = emotion_scores.get('sadness', 0)\n",
    "                        surprise = emotion_scores.get('surprise', 0)\n",
    "                        neutral = emotion_scores.get('neutral', 0)\n",
    "                        anger_disgust = emotion_scores.get('anger_disgust', 0)\n",
    "\n",
    "                        # Add the scores to the corresponding year and month\n",
    "                        if (article[2], article[3]) not in year_emotions:\n",
    "                            year_emotions[(article[2], article[3])] = {\n",
    "                                'optimism': [],\n",
    "                                'anxiety': [],\n",
    "                                'sadness': [],\n",
    "                                'surprise': [],\n",
    "                                'neutral': [],\n",
    "                                'anger_disgust': []\n",
    "                            }\n",
    "\n",
    "                        year_emotions[(article[2], article[3])]['optimism'].append(optimism)\n",
    "                        year_emotions[(article[2], article[3])]['anxiety'].append(anxiety)\n",
    "                        year_emotions[(article[2], article[3])]['sadness'].append(sadness)\n",
    "                        year_emotions[(article[2], article[3])]['surprise'].append(surprise)\n",
    "                        year_emotions[(article[2], article[3])]['neutral'].append(neutral)\n",
    "                        year_emotions[(article[2], article[3])]['anger_disgust'].append(anger_disgust)\n",
    "\n",
    "                # Clear the batch after processing\n",
    "                batch_articles.clear()\n",
    "\n",
    "    # Read the existing CSV file into memory to modify it\n",
    "    with open(ticker_graph_csv, mode='r', newline='', encoding='utf-8') as graph_file:\n",
    "        reader = csv.DictReader(graph_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Update the rows with new emotional scores\n",
    "    updated_rows = []\n",
    "    for (year, month), emotions in year_emotions.items():\n",
    "        avg_optimism = sum(emotions['optimism']) / len(emotions['optimism'])\n",
    "        avg_anxiety = sum(emotions['anxiety']) / len(emotions['anxiety'])\n",
    "        avg_sadness = sum(emotions['sadness']) / len(emotions['sadness'])\n",
    "        avg_surprise = sum(emotions['surprise']) / len(emotions['surprise'])\n",
    "        avg_neutral = sum(emotions['neutral']) / len(emotions['neutral'])\n",
    "        avg_anger_disgust = sum(emotions['anger_disgust']) / len(emotions['anger_disgust'])\n",
    "\n",
    "        # Update all rows that match the year\n",
    "        for row in rows:\n",
    "            if row['year'] == str(year):\n",
    "                row['optimism'] = avg_optimism\n",
    "                row['anxiety'] = avg_anxiety\n",
    "                row['sadness'] = avg_sadness\n",
    "                row['surprise'] = avg_surprise\n",
    "                row['neutral'] = avg_neutral\n",
    "                row['anger_disgust'] = avg_anger_disgust\n",
    "\n",
    "    # Write the updated rows back to the CSV\n",
    "    with open(ticker_graph_csv, mode='w', newline='', encoding='utf-8') as graph_file:\n",
    "        fieldnames = ['date', 'stock_price', 'year', 'optimism', 'anxiety', 'sadness', 'surprise', 'neutral', 'anger_disgust']\n",
    "        writer = csv.DictWriter(graph_file, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"Ticker graph updated with average emotional scores for each year in {ticker_graph_csv}.\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    ticker_symbol = input(\"Enter the ticker symbol of the company: \").upper()\n",
    "    company_name = input(\"Enter the company name: \")\n",
    "    \n",
    "    if company_name:\n",
    "        print(f\"Processing news articles for {company_name} ({ticker_symbol})...\")\n",
    "\n",
    "        # Set the CSV file where news articles are saved\n",
    "        csv_file = f\"{ticker_symbol}_news.csv\"\n",
    "        ticker_graph_csv = f\"{ticker_symbol}_graph.csv\"\n",
    "\n",
    "        # Process articles in batches and update the graph CSV with average emotional scores for each year\n",
    "        process_articles_and_update_graph(csv_file, company_name, ticker_graph_csv, batch_size=10)\n",
    "    else:\n",
    "        print(\"Could not fetch company name. Please check the ticker symbol.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
