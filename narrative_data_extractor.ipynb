{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /opt/homebrew/lib/python3.13/site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/alyssaspasic/Library/Python/3.13/lib/python/site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (2025.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/homebrew/lib/python3.13/site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.13/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/homebrew/lib/python3.13/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alyssaspasic/Library/Python/3.13/lib/python/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.13/site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alyssaspasic/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/homebrew/lib/python3.13/site-packages (4.13.3)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.13/site-packages (1.65.4)\n",
      "Requirement already satisfied: lxml in /opt/homebrew/lib/python3.13/site-packages (5.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.13/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/homebrew/lib/python3.13/site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.13/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.13/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.13/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: lxml in /opt/homebrew/lib/python3.13/site-packages (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install requests\n",
    "!pip install requests beautifulsoup4 openai lxml\n",
    "!pip install newspaper3k\n",
    "!pip install lxml[html_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        date stock_price  year  optimism   anxiety   sadness  surprise  \\\n",
      "Ticker                                                                        \n",
      "0      2010-01-01    6.440331  2010  5.749080  3.841911  3.669062  5.357401   \n",
      "1      2010-02-01    5.860126  2010  5.582458  4.470871  3.067430  5.715264   \n",
      "2      2010-03-01    6.289261  2010  6.368466  2.349075  2.072540  5.178318   \n",
      "3      2010-04-01    7.101188  2010  5.542698  2.125746  1.935110  3.925065   \n",
      "4      2010-05-01    8.015430  2010  5.661796  4.473415  2.612138  3.053635   \n",
      "\n",
      "Price    neutral anger_disgust  \n",
      "Ticker                          \n",
      "0       4.393373      2.564841  \n",
      "1       5.216639      4.771540  \n",
      "2       4.697012      3.025596  \n",
      "3       4.024832      4.787747  \n",
      "4       5.050352      4.670469  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/wk/drd22rx56sq26c5q972b54cr0000gn/T/ipykernel_60369/2951289065.py:42: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  stock_data_monthly = stock_data.resample('MS', on='Date').first()  # 'MS' stands for Month Start\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch stock data\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    # Fetch stock data\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    # Return only the \"Close\" prices and the Date\n",
    "    stock_data = stock_data[['Close']].reset_index()\n",
    "    return stock_data\n",
    "\n",
    "# Example: Fetch data for Apple (AAPL) from January 1, 2010 to March 1, 2025\n",
    "ticker = 'AAPL'\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2025-03-01'\n",
    "stock_data = fetch_stock_data(ticker, start_date, end_date)\n",
    "\n",
    "# Placeholder emotional tone data (assuming a simple range from 0 to 10)\n",
    "# Simulate some values, in real case you would replace them with actual analysis\n",
    "np.random.seed(42)  # For reproducibility\n",
    "emotion_data = {\n",
    "    'optimism': np.random.uniform(5, 7, len(stock_data)),\n",
    "    'anxiety': np.random.uniform(2, 5, len(stock_data)),\n",
    "    'sadness': np.random.uniform(1, 4, len(stock_data)),\n",
    "    'surprise': np.random.uniform(3, 6, len(stock_data)),\n",
    "    'neutral': np.random.uniform(4, 6, len(stock_data)),\n",
    "    'anger_disgust': np.random.uniform(2, 5, len(stock_data))\n",
    "}\n",
    "\n",
    "# Add year, stock price and emotion data to the dataframe\n",
    "stock_data['year'] = stock_data['Date'].dt.year\n",
    "stock_data['optimism'] = emotion_data['optimism']\n",
    "stock_data['anxiety'] = emotion_data['anxiety']\n",
    "stock_data['sadness'] = emotion_data['sadness']\n",
    "stock_data['surprise'] = emotion_data['surprise']\n",
    "stock_data['neutral'] = emotion_data['neutral']\n",
    "stock_data['anger_disgust'] = emotion_data['anger_disgust']\n",
    "stock_data['stock_price'] = stock_data['Close']  # Renaming Close to stock_price\n",
    "\n",
    "# Resample to get only the first trading day of each month\n",
    "stock_data_monthly = stock_data.resample('MS', on='Date').first()  # 'MS' stands for Month Start\n",
    "\n",
    "# Reset the index to bring the 'Date' back as a column\n",
    "stock_data_monthly = stock_data_monthly.reset_index()\n",
    "\n",
    "# Rename 'Date' to 'date'\n",
    "stock_data_monthly = stock_data_monthly.rename(columns={'Date': 'date'})\n",
    "\n",
    "# Select the columns to match the required format\n",
    "final_data = stock_data_monthly[['date', 'stock_price', 'year', 'optimism', 'anxiety', 'sadness', 'surprise', 'neutral', 'anger_disgust']]\n",
    "\n",
    "# Save to a new CSV file (this will create a new file every time the script is run)\n",
    "final_data.to_csv('stock_data_with_emotions_monthly.csv', index=False)\n",
    "\n",
    "# Print the first few rows to verify the output\n",
    "print(final_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from newspaper import Article\n",
    "from urllib.parse import quote_plus\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set GNews API key\n",
    "GNEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "\n",
    "# List of common suffixes to remove\n",
    "SUFFIXES = [' Inc.', ' Ltd.', ' LLC', ' Corp.', ' Corporation', ' Co.', ' Group']\n",
    "\n",
    "# Function to get company name from ticker symbol using Yahoo Finance\n",
    "def get_company_name_from_ticker(ticker):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        company_name = stock.info['longName']\n",
    "        \n",
    "        # Remove common corporate suffixes from the company name\n",
    "        for suffix in SUFFIXES:\n",
    "            if company_name.endswith(suffix):\n",
    "                company_name = company_name.replace(suffix, '').strip()\n",
    "        \n",
    "        return company_name\n",
    "    except KeyError:\n",
    "        print(f\"Error: Company name not found for ticker {ticker}. Using fallback name.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}. Using fallback name.\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch articles for a given year\n",
    "def fetch_articles_for_year(api_key, company_name, year):\n",
    "    start_date = f'{year}-01-01T00:00:00Z'\n",
    "    end_date = f'{year}-12-31T23:59:59Z'\n",
    "    query = quote_plus(f'\"{company_name}\"')  # URL encode the company name for exact match\n",
    "    url = f'https://gnews.io/api/v4/search?q={query}&from={start_date}&to={end_date}&lang=en&max=10&token={api_key}&in=title,description'\n",
    "    \n",
    "    print(f\"Requesting URL: {url}\")  # Debugging line to print the URL\n",
    "    for _ in range(3):  # Retry up to 3 times\n",
    "        response = requests.get(url)\n",
    "        print(f\"Response status: {response.status_code}\")  # Debugging line to print the response status\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get('articles', [])\n",
    "        else:\n",
    "            print(f\"Error fetching articles for {year} (Status {response.status_code}). Retrying...\")\n",
    "            time.sleep(2)\n",
    "    return []\n",
    "\n",
    "# Function to fetch articles across multiple years\n",
    "def fetch_articles(api_key, company_name):\n",
    "    current_year = datetime.now().year\n",
    "    all_articles = []\n",
    "    for year in range(2010, current_year + 1):\n",
    "        print(f\"Fetching articles for {year}...\")\n",
    "        articles = fetch_articles_for_year(api_key, company_name, year)\n",
    "        if articles:\n",
    "            all_articles.extend(articles)\n",
    "        else:\n",
    "            print(f\"No articles found for {year}.\")\n",
    "        time.sleep(2)\n",
    "    return all_articles\n",
    "\n",
    "# Function to scrape the full content using Newspaper3k\n",
    "def scrape_full_content(url):\n",
    "    article = Article(url)\n",
    "    for _ in range(3):  # Retry up to 3 times\n",
    "        try:\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            return article.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url}: {e}. Retrying...\")\n",
    "            time.sleep(2)\n",
    "    return \"Error fetching full content.\"\n",
    "\n",
    "# Function to save articles to CSV with full content\n",
    "def save_articles_to_csv_with_full_content(articles, filename):\n",
    "    headers = ['Title', 'PublishedAt', 'FullContent', 'URL']\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        for article in articles:\n",
    "            title = article['title']\n",
    "            published_at = article['publishedAt']\n",
    "            url = article['url']\n",
    "            full_content = scrape_full_content(url)\n",
    "            if full_content:\n",
    "                writer.writerow([title, published_at, full_content, url])\n",
    "    print(f\"Articles saved to {filename}\")\n",
    "\n",
    "# Main function to get company name and save articles\n",
    "def main():\n",
    "    ticker_symbol = input(\"Enter the ticker symbol of the company: \").upper()\n",
    "    \n",
    "    # Get company name using Yahoo Finance API \n",
    "    company_name = get_company_name_from_ticker(ticker_symbol) \n",
    "    \n",
    "    print(f\"Fetching news articles for {company_name} ({ticker_symbol})...\")\n",
    "    \n",
    "    articles_data = fetch_articles(GNEWS_API_KEY, company_name)\n",
    "    \n",
    "    if articles_data:\n",
    "        # Save articles to CSV with the ticker symbol in the filename\n",
    "        filename = f\"{ticker_symbol}_news.csv\"\n",
    "        save_articles_to_csv_with_full_content(articles_data, filename)\n",
    "        \n",
    "        # Display the first 5 articles for confirmation\n",
    "        for article in articles_data[:5]:\n",
    "            print(f\"Title: {article['title']}\")\n",
    "            print(f\"PublishedAt: {article['publishedAt']}\")\n",
    "            print(f\"URL: {article['url']}\")\n",
    "            print(f\"Full Content: {scrape_full_content(article['url'])}\\n\")\n",
    "    else:\n",
    "        print(f\"No articles found for {company_name}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
